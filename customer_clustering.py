# è¥é”€æ•°æ®åˆ†æå¸ˆ
print("å¼€å§‹å®¢æˆ·èšç±»åˆ†æ...")
print("æ­¥éª¤1: å¯¼å…¥å¿…è¦çš„åº“")

try:
    # 1. å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.preprocessing import StandardScaler
    from sklearn.cluster import KMeans
    from sklearn.metrics import silhouette_score
    import warnings
    warnings.filterwarnings('ignore')
    print("âœ“ æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸï¼")

except ImportError as e:
    print(f"âŒ å¯¼å…¥åº“æ—¶å‡ºé”™: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰å¿…éœ€çš„åº“ã€‚åœ¨ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š")
    print("pip install pandas numpy scikit-learn matplotlib seaborn")
    exit()

# è®¾ç½®å›¾è¡¨æ ·å¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

print("\næ­¥éª¤2: åŠ è½½æ‚¨çš„æ•°æ®")

csv_file_path = "E:\\å¤§äºŒä¸Šææ–™\\å¸‚åœºè¥é”€å­¦åŸç†\\ä½œä¸šå››\\used_data.csv"  # è¯·å°† 'your_data.csv' æ›¿æ¢ä¸ºæ‚¨çš„å®é™…æ–‡ä»¶å
try:
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_file_path)
    print(f"âœ“ æ•°æ®æ–‡ä»¶åŠ è½½æˆåŠŸ: {csv_file_path}")
    
except FileNotFoundError:
    print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {csv_file_path}")
    print("è¯·æ£€æŸ¥ï¼š")
    print("1. æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
    print("2. æ–‡ä»¶åæ˜¯å¦æ‹¼å†™æ­£ç¡®ï¼ˆåŒ…æ‹¬.csvåç¼€ï¼‰")
    print("3. æ–‡ä»¶æ˜¯å¦åœ¨æŒ‡å®šç›®å½•ä¸­")
    exit()
except Exception as e:
    print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    exit()

print(f"æ•°æ®å½¢çŠ¶: {df.shape} (è¡Œæ•°: {df.shape[0]}, åˆ—æ•°: {df.shape[1]})")

print("\næ­¥éª¤3: æ£€æŸ¥æ•°æ®ç»“æ„å’Œåˆ—å")
print("æ•°æ®å‰5è¡Œ:")
print(df.head())

print("\næ•°æ®åˆ—å:")
print(df.columns.tolist())

print("\næ•°æ®åŸºæœ¬ä¿¡æ¯:")
print(df.info())

#CSVæœ‰è¡¨å¤´ä¸”åˆ—åå°±æ˜¯ä»¥ä¸‹åç§°ï¼Œ
expected_columns = {
    'customer_id': df.columns[0],  # ç¬¬ä¸€åˆ—ï¼šé¡¾å®¢id
    'total_spent': df.columns[1],   # ç¬¬äºŒåˆ—ï¼šæ€»é‡‘é¢æ•°
    'num_orders': df.columns[2],    # ç¬¬ä¸‰åˆ—ï¼šè®¢å•æ•°é‡
    'avg_order_value': df.columns[3],  # ç¬¬å››åˆ—ï¼šå¹³å‡è®¢å•ä»·å€¼
    'Electronics_amount': df.columns[4]  # ç¬¬äº”åˆ—ï¼šç”µå­äº§å“æ¶ˆè´¹
}

print("æ£€æµ‹åˆ°çš„åˆ—åæ˜ å°„:")
for key, value in expected_columns.items():
    print(f"  {key}: {value}")

# é‡å‘½ååˆ—ä»¥ä¾¿ä»£ç ç»Ÿä¸€å¤„ç†
df_clean = df.rename(columns={
    expected_columns['customer_id']: 'customer_id',
    expected_columns['total_spent']: 'total_spent',
    expected_columns['num_orders']: 'num_orders',
    expected_columns['avg_order_value']: 'avg_order_value',
    expected_columns['Electronics_amount']: 'Electronics_amount'
})

print("\næ­¥éª¤4: æ•°æ®è´¨é‡æ£€æŸ¥")
print("æ•°æ®åŸºæœ¬ä¿¡æ¯:")
print(df_clean.info())

print("\næè¿°æ€§ç»Ÿè®¡:")
print(df_clean[['total_spent', 'num_orders', 'avg_order_value', 'Electronics_amount']].describe())

print("\nç¼ºå¤±å€¼æ£€æŸ¥:")
missing_values = df_clean[['total_spent', 'num_orders', 'avg_order_value', 'Electronics_amount']].isnull().sum()
print(missing_values)

# å¤„ç†ç¼ºå¤±å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
if missing_values.sum() > 0:
    print("å‘ç°ç¼ºå¤±å€¼ï¼Œä½¿ç”¨ä¸­ä½æ•°å¡«å……...")
    df_clean = df_clean.fillna(df_clean[['total_spent', 'num_orders', 'avg_order_value', 'Electronics_amount']].median())
    print("âœ“ ç¼ºå¤±å€¼å¤„ç†å®Œæˆ")

print("\næ­¥éª¤5: é€‰æ‹©èšç±»å˜é‡")
# é€‰æ‹©å››ä¸ªå…³é”®å˜é‡è¿›è¡Œèšç±»
cluster_vars = ['total_spent', 'num_orders', 'avg_order_value', 'Electronics_amount']
cluster_data = df_clean[cluster_vars]

print("âœ“ é€‰æ‹©çš„èšç±»å˜é‡:")
for i, var in enumerate(cluster_vars, 1):
    print(f"  {i}. {var}")

print("\næ­¥éª¤6: æ•°æ®æ ‡å‡†åŒ–")
# æ•°æ®æ ‡å‡†åŒ– - è¿™æ˜¯éå¸¸é‡è¦çš„ä¸€æ­¥ï¼
scaler = StandardScaler()
cluster_data_scaled = scaler.fit_transform(cluster_data)

# è½¬æ¢ä¸ºDataFrameä¾¿äºæŸ¥çœ‹
cluster_data_scaled_df = pd.DataFrame(cluster_data_scaled, columns=cluster_vars)
print("âœ“ æ•°æ®æ ‡å‡†åŒ–å®Œæˆ")
print("\næ ‡å‡†åŒ–åçš„æ•°æ®ç»Ÿè®¡:")
print(cluster_data_scaled_df.describe())

print("\næ­¥éª¤7: å¯»æ‰¾æœ€ä¼˜Kå€¼")
print("æ­£åœ¨è®¡ç®—ä¸åŒKå€¼ä¸‹çš„èšç±»æ•ˆæœ...")

# æµ‹è¯•ä¸åŒçš„Kå€¼ï¼ˆä»2åˆ°10ï¼‰
k_range = range(2, 11)
inertias = []
silhouette_scores = []

for k in k_range:
    # åˆ›å»ºKMeansæ¨¡å‹
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(cluster_data_scaled)
    
    # è®°å½•æƒ¯æ€§ï¼ˆç°‡å†…å¹³æ–¹å’Œï¼‰
    inertias.append(kmeans.inertia_)
    
    # è®¡ç®—è½®å»“ç³»æ•°
    labels = kmeans.labels_
    score = silhouette_score(cluster_data_scaled, labels)
    silhouette_scores.append(score)
    
    print(f"K={k}: æƒ¯æ€§ = {kmeans.inertia_:.2f}, è½®å»“ç³»æ•° = {score:.4f}")

print("\næ­¥éª¤8: å¯è§†åŒ–Kå€¼é€‰æ‹©ç»“æœ")
# åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# è‚˜éƒ¨æ³•åˆ™å›¾
ax1.plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)
ax1.set_xlabel('èšç±»æ•°é‡ (K)')
ax1.set_ylabel('æƒ¯æ€§ (Inertia)')
ax1.set_title('è‚˜éƒ¨æ³•åˆ™ - å¯»æ‰¾æœ€ä¼˜Kå€¼')
ax1.grid(True, alpha=0.3)

# åœ¨è‚˜éƒ¨å›¾ä¸Šæ ‡è®°å¯èƒ½çš„æ‹ç‚¹
elbow_k = 4  # æ ¹æ®å›¾å½¢åˆ¤æ–­ï¼Œå¯ä»¥è°ƒæ•´
ax1.axvline(x=elbow_k, color='red', linestyle='--', alpha=0.7, label=f'å¯èƒ½æ‹ç‚¹ K={elbow_k}')
ax1.legend()

# è½®å»“ç³»æ•°å›¾
ax2.plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=8)
ax2.set_xlabel('èšç±»æ•°é‡ (K)')
ax2.set_ylabel('è½®å»“ç³»æ•°')
ax2.set_title('è½®å»“ç³»æ•° - å¯»æ‰¾æœ€ä¼˜Kå€¼')
ax2.grid(True, alpha=0.3)

# æ ‡è®°æœ€ä½³è½®å»“ç³»æ•°
best_k_index = np.argmax(silhouette_scores)
best_k = k_range[best_k_index]
best_score = silhouette_scores[best_k_index]

ax2.axvline(x=best_k, color='red', linestyle='--', alpha=0.7, 
            label=f'æœ€ä½³Kå€¼: {best_k} (åˆ†æ•°: {best_score:.3f})')
ax2.legend()

plt.tight_layout()
plt.savefig('k_value_selection.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"âœ“ å›¾è¡¨å·²ä¿å­˜ä¸º 'k_value_selection.png'")
print(f"æ ¹æ®è½®å»“ç³»æ•°ï¼Œå»ºè®®çš„æœ€ä½³Kå€¼æ˜¯: {best_k}")
print(f"å¯¹åº”çš„è½®å»“ç³»æ•°: {best_score:.4f}")

print("\næ­¥éª¤9: æ‰§è¡Œæœ€ç»ˆèšç±»")
# ä½¿ç”¨æœ€ä½³Kå€¼è¿›è¡Œæœ€ç»ˆèšç±»
final_k = best_k  # æ‚¨ä¹Ÿå¯ä»¥æ ¹æ®å›¾è¡¨æ‰‹åŠ¨é€‰æ‹©ï¼Œæ¯”å¦‚é€‰æ‹© elbow_k

print(f"ä½¿ç”¨ K={final_k} è¿›è¡Œæœ€ç»ˆèšç±»...")

final_kmeans = KMeans(n_clusters=final_k, random_state=42, n_init=10)
final_kmeans.fit(cluster_data_scaled)

# å°†èšç±»ç»“æœæ·»åŠ åˆ°åŸå§‹æ•°æ®
df_clean['cluster'] = final_kmeans.labels_

print("âœ“ èšç±»å®Œæˆ")
print("\nå„ç°‡å®¢æˆ·åˆ†å¸ƒ:")
cluster_counts = df_clean['cluster'].value_counts().sort_index()
for cluster_id, count in cluster_counts.items():
    percentage = (count / len(df_clean)) * 100
    print(f"ç°‡ {cluster_id}: {count} ä½å®¢æˆ· ({percentage:.1f}%)")

print("\næ­¥éª¤10: åˆ†æèšç±»ç»“æœ")
# åˆ†ææ¯ä¸ªç°‡çš„ç‰¹å¾
print("\nå„ç°‡åœ¨å…³é”®å˜é‡ä¸Šçš„å¹³å‡å€¼:")
cluster_profile = df_clean.groupby('cluster')[cluster_vars].mean()
print(cluster_profile.round(2))

# è®¡ç®—ä¸æ€»ä½“å‡å€¼çš„ç›¸å¯¹å·®å¼‚
print("\nå„ç°‡ä¸æ€»ä½“å‡å€¼çš„ç›¸å¯¹å·®å¼‚ (%):")
relative_diff = (cluster_profile / cluster_data.mean() - 1) * 100
print(relative_diff.round(2))

print("\næ­¥éª¤11: å¯è§†åŒ–èšç±»ç‰¹å¾")
# åˆ›å»ºç°‡ç‰¹å¾å¯è§†åŒ–
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
axes = axes.ravel()

colors = ['#FF9999', '#66B2FF', '#99FF99', '#FFD700', '#FFB6C1']

for i, var in enumerate(cluster_vars):
    # ä¸ºæ¯ä¸ªå˜é‡åˆ›å»ºç®±çº¿å›¾
    box_data = [df_clean[df_clean['cluster'] == cluster][var] for cluster in range(final_k)]
    axes[i].boxplot(box_data, labels=range(final_k), patch_artist=True)
    axes[i].set_title(f'{var} çš„åˆ†å¸ƒ by ç°‡')
    axes[i].set_ylabel(var)
    axes[i].set_xlabel('ç°‡')
    
    # æ·»åŠ é¢œè‰²
    for patch, color in zip(axes[i].artists, colors[:final_k]):
        patch.set_facecolor(color)

plt.suptitle('å„å˜é‡åœ¨ä¸åŒç°‡ä¸­çš„åˆ†å¸ƒ', fontsize=16)
plt.tight_layout()
plt.savefig('cluster_distributions.png', dpi=300, bbox_inches='tight')
plt.show()

print("\næ­¥éª¤12: åˆ›å»ºç»¼åˆç‰¹å¾å¯¹æ¯”å›¾")
plt.figure(figsize=(14, 10))

# å‡†å¤‡æ•°æ®ç”¨äºæ¡å½¢å›¾
melted_data = df_clean.melt(id_vars=['cluster'], value_vars=cluster_vars, 
                      var_name='æŒ‡æ ‡', value_name='å€¼')

# åˆ›å»ºåˆ†ç»„æ¡å½¢å›¾
plt.subplot(2, 1, 1)
sns.barplot(data=melted_data, x='cluster', y='å€¼', hue='æŒ‡æ ‡', palette='viridis')
plt.title('å„å®¢æˆ·ç°‡çš„ç‰¹å¾å¯¹æ¯”', fontsize=14)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

# åˆ›å»ºå®¢æˆ·åˆ†å¸ƒé¥¼å›¾
plt.subplot(2, 1, 2)
colors = plt.cm.Set3(np.linspace(0, 1, final_k))
plt.pie(cluster_counts.values, labels=[f'ç°‡ {i}' for i in cluster_counts.index], 
        autopct='%1.1f%%', startangle=90, colors=colors)
plt.title('å®¢æˆ·ç°‡åˆ†å¸ƒæ¯”ä¾‹', fontsize=14)

plt.tight_layout()
plt.savefig('cluster_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

print("\næ­¥éª¤13: ç”Ÿæˆè¯¦ç»†çš„ä¸šåŠ¡è§£è¯»æŠ¥å‘Š")
print("=" * 60)
print("           å®¢æˆ·èšç±»åˆ†æä¸šåŠ¡æŠ¥å‘Š")
print("=" * 60)

print(f"\nğŸ“Š åˆ†ææ€»ç»“:")
print(f"   â€¢ æ€»å®¢æˆ·æ•°: {len(df_clean)}")
print(f"   â€¢ æœ€ä¼˜èšç±»æ•°: {final_k}")
print(f"   â€¢ èšç±»è´¨é‡ (è½®å»“ç³»æ•°): {best_score:.3f}")
print(f"   â€¢ è½®å»“ç³»æ•°è§£è¯»: {'ä¼˜ç§€' if best_score > 0.7 else 'è‰¯å¥½' if best_score > 0.5 else 'ä¸€èˆ¬'}")

print(f"\nğŸ‘¥ å„å®¢æˆ·ç¾¤è¯¦ç»†æè¿°:")

# ä¸ºæ¯ä¸ªç°‡ç”Ÿæˆè¯¦ç»†æè¿°
for cluster_id in range(final_k):
    cluster_data = df_clean[df_clean['cluster'] == cluster_id]
    cluster_mean = cluster_data[cluster_vars].mean()
    total_mean = df_clean[cluster_vars].mean()
    
    print(f"\nğŸ¯ å®¢æˆ·ç¾¤ {cluster_id} (å æ¯”: {len(cluster_data)/len(df_clean)*100:.1f}%)")
    print(f"   ğŸ“ˆ å…³é”®æŒ‡æ ‡:")
    print(f"      â€¢ æ€»æ¶ˆè´¹: Â¥{cluster_mean['total_spent']:.0f} "
          f"({'+' if cluster_mean['total_spent'] > total_mean['total_spent'] else ''}"
          f"{(cluster_mean['total_spent']/total_mean['total_spent']-1)*100:.0f}%)")
    print(f"      â€¢ è®¢å•æ•°: {cluster_mean['num_orders']:.1f} "
          f"({'+' if cluster_mean['num_orders'] > total_mean['num_orders'] else ''}"
          f"{(cluster_mean['num_orders']/total_mean['num_orders']-1)*100:.0f}%)")
    print(f"      â€¢ å®¢å•ä»·: Â¥{cluster_mean['avg_order_value']:.0f} "
          f"({'+' if cluster_mean['avg_order_value'] > total_mean['avg_order_value'] else ''}"
          f"{(cluster_mean['avg_order_value']/total_mean['avg_order_value']-1)*100:.0f}%)")
    print(f"      â€¢ ç”µå­äº§å“æ¶ˆè´¹: Â¥{cluster_mean['Electronics_amount']:.0f} "
          f"({'+' if cluster_mean['Electronics_amount'] > total_mean['Electronics_amount'] else ''}"
          f"{(cluster_mean['Electronics_amount']/total_mean['Electronics_amount']-1)*100:.0f}%)")
   
# ä¿å­˜ç»“æœ
output_file = 'customer_clustering_results.csv'
df_clean.to_csv(output_file, index=False, encoding='utf-8-sig')
print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
print(f"å›¾è¡¨å·²ä¿å­˜ä¸º: k_value_selection.png, cluster_distributions.png, cluster_comparison.png")


# æ˜¾ç¤ºå®Œæˆæ¶ˆæ¯
print("å®¢æˆ·èšç±»åˆ†æå·²å®Œæˆ")
